---
title: "PS05"
author: "Michael Wethington"
date: "9/23/2020"
output: pdf_document
---

**Metropolis Sampler**

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(boot)

#Choose Starting Values
df <- read.csv("C:/Users/wmichael/Google Drive/BEE569/labs/l5/data/plants.csv")

current_b0 <- rnorm(1, 0, 1)
current_b1 <- rnorm(1, 0, 1)

b0_accepted <- c()
b1_accepted <- c()


N = 1000
step_sigma <- .14

#Scale the elevation 
df$Elevation <- scale(df$Elevation)

for(i in 1:N){
  
  
  next_b0 <- current_b0+rnorm(1, 0, step_sigma)
  next_b1 <- current_b1+rnorm(1, 0, step_sigma)
  
  accept_probability <- sum(dbinom(df$PlantEnd, df$Plants, inv.logit(next_b0 + next_b1 * df$Elevation), log = T)) +
                              dnorm(next_b0, 0, 1, log = T) + dnorm(next_b1, 0, 1, log=T) -
                              
                              sum(dbinom(df$PlantEnd, df$Plants, inv.logit(current_b0 + current_b1 * df$Elevation), log = T)) -
                              dnorm(current_b0, 0, 1, log =T) - dnorm(current_b1, 0,1,log=T)
  
  
  if(accept_probability > runif(1,0,1)){
    
    b0_accepted <- c(b0_accepted, next_b0)
    b1_accepted <- c(b1_accepted, next_b1)
  }
  
}


plot(b0_accepted, b1_accepted)

```

**Ex. 6: Why is there a sum in the exponent for likelihood?** 



**Ex. 7: Construct a Gibbs Sampler**

```{r}


gibbs.dat <- read.csv("C:/Users/wmichael/Google Drive/BEE569/labs/l5/data/gibbs.csv")
names(gibbs.dat)[names(gibbs.dat) == "X2.8"] <- "vector"




gibbs <- function(N.iters, gamma, omega_square, alpha, beta){
  
  #Function parameters
  gamma <- gamma
  omega_square <- omega_square
  alpha <- alpha
  beta <- beta
  
  #storage Vectors 
  mu <- c()
  tau <- c()
  mu[1] <- rnorm(n = 1,mean=gamma,omega_square)# Mu
  tau[1] <- rgamma(1,alpha,beta) # Tau
  
  # number of iterations
  n.iter <- N.iters
  
  # iterate through and sample
  for (t in 2:n.iter){
    
    mu[t] <- rnorm(n = 1, ((tau[t-1]*sum(gibbs.dat$vector))+(gamma/omega_square))/(length(gibbs.dat$vector)*tau[t-1]+(1/omega_square)), 
                   1/((length(gibbs.dat$V1)*tau[t-1])+(1/omega_square))) # update  dependent on x[t-1]
    
    
    tau[t] <- rgamma(1, (alpha + 0.5*length(gibbs.dat$vector)), (beta + 0.5*(sum(((gibbs.dat$vector-mu[t])^2))))) 
  }

  #Create and return a dataframe with the posteriors of mu and tau
  df <- data.frame(mu, tau)
  
return(df)
  
}


```

**Ex 08: USe three chains to check convergence, and provide polots of chains and the posterior histograms for both $\mu$ and $\tau$ **

```{r}

#Plot histograms of tau and mu

df<- gibbs(1000, 1, 1, 10, .5)
# scatterplot of bivariate (x,) pairs
plot(df$mu, df$tau)
# histogram of marginal distribution for x
# marginalized out mu
hist(df$mu, breaks = 20)
# histogram of marginal distribution for 
# marginalized out tau
hist(df$tau, breaks = 20)



#
df1<- gibbs(1000, 1, 1, 10, .5)
plot(df1$mu, type= 'l')
hist(df$mu, breaks = 20)
plot(df1$tau, type= 'l')
hist(df$tau, breaks = 20)


df2 <- gibbs(1000, 10, 1, 10, .5)
plot(df2$mu, type= 'l')
hist(df2$mu, breaks = 20)
plot(df2$tau, type= 'l')
hist(df2$tau, breaks = 20)

df3 <- gibbs(1000, 15, 1, 10, .5)
plot(df3$mu, type= 'l')
hist(df3$mu, breaks = 20)
plot(df3$tau, type= 'l')
hist(df3$tau, breaks = 20)
```





**Ex 09: What are the 95% credible intervals for $\mu$ and $\tau$?**

```{r}

```


**Ex 10: Do your answers to Q8 and Q9 make sense? Histogram the original data and plot the posterior distribution implid by you posterior mean. Does the plot make sense? Plot the distributions of $\mu$ and $\tau$

```{r}
posterior <-rnorm(1000, mean = df1$mu, sd = 1/df$tau )
post.hist <- hist(posterior, col = "lightblue")

raw.dat <- hist(gibbs.dat$vector)

plot(post.hist) # Plot 1st histogram using a transparent color
plot(raw.dat, add = TRUE) # Add 2nd histogram using different color
```

